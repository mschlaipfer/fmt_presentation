\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{uniinput}
\usepackage[english]{babel}

\renewcommand{\L}{\mathcal{L}}
\newcommand{\K}{\mathcal{K}}
\newcommand{\A}{\mathcal{A}}
\renewcommand{\P}{\mathcal{P}}

\usetheme{Madrid}
\usecolortheme{seahorse}
\setbeamertemplate{navigation symbols}{}

%\title
%\author

\begin{document}

\begin{frame}
	\titlepage
\end{frame}

% \begin{frame}
% 	\frametitle{Inhalt}
% 	\tableofcontents
% \end{frame}

\begin{frame}
	
	Goal: Machine-independent characterization of complexity classes
	\begin{definition}
		Let $\mathcal{K}$ be a complexity class and $\mathcal{L}$ a logic. We say that $\L$ captures $\K$ iff the following holds:
		\begin{enumerate}
			\item For every sentence $Φ$ of $\L$ and every finite structure $\A$, it is decidable in $\K$ whether $\A \vDash Φ$;
			\item For every property $\P$ of finite structures decidable in $\K$ there is a sentence $Φ$ of $\L$ such that $\A$ has property $\P$ iff $\A \vDash Φ$.
		\end{enumerate}
	\end{definition}
	
	\medskip
	
	Briefly: We say that $\L$ captures $\K$ if the properties that can be decided in $\K$ are exactly those that can be defined in $\L$.
	
	\medskip
	
	Application: Show that complexity classes are different by showing that their capturing logics are different.
\end{frame}

\begin{frame}
\frametitle{Fagin's Theorem}
Reminder: $\exists SO$ is second order predicate logic with only existential quantifiers.
  \begin{theorem}[Fagin]
    $∃SO$ captures $NP$.
  \end{theorem}
  First machine-independent characterization of a complexity class   
\end{frame}
\begin{frame}
 \begin{corollary}
  $\forall SO$ captures $coNP$.
 \end{corollary}
  Application to the $P = NP$ problem:
  \begin{equation*}
   \forall SO \neq \exists SO \Rightarrow coNP \neq NP \Rightarrow P \neq NP
  \end{equation*}

\end{frame}

\begin{frame}
 \frametitle{Proof of Fagin's theorem}
 Easy direction: Let $Φ$ be a sentence of $\exists SO$ and $\A$ a structure. Suppose $Φ = \exists S_1 … \exists S_n φ$ with $φ$ FO. Checking whether $\A \vDash Φ$ can be done by guessing $S_1,…,S_n$ and then checking $\A \vDash φ(S_1,…,S_n)$. The latter part is polynomial in $\|\A\|$.
 
 \medskip
 
 Hard direction: Similar to proof of Trakhtenbrot's theorem, but a bit more involved.
 \begin{itemize}
 	\item Given: ND Turing machine $M$ that takes encodings of structures as input and tests whether property $\P$ holds.
 	\item If $n$ is the size of the structure, assume that the machine runs in time $n^k$ for some $k$ and visits the entire input.
 	\item Can describe both time and space on tape as $k$-tuples of elements of the model.
 \end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Hard direction, ctd.}
	We seek to construct a sentence
	\begin{equation*}
	∃L ∃T_0 ∃T_1 ∃T_{\_} ∃H_{q_0} … ∃H_{q_{m-1}} Ψ,
	\end{equation*}
	where $L$ is binary and the other predicates are $2k$-ary.
	
	Intended interpretation of the predicates:
	\begin{itemize}
	\item $L$ is a linear order. Define lexicographic order $<_k$ based on $L$.
	\item $T_{*}(\bar{p}, \bar{t}) \leftrightarrow$ tape contains $*$ at position $\bar{p}$ and time $\bar{t}$ for $* ∈ \{0, 1, \_\}$.
	\item $H_{q_i}(\bar{p},\bar{t}) \leftrightarrow$ at time $\bar{t}$, the machine is in state $q_{i}$ and the head is in position $\bar{t}$.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Construction of $Ψ$}
	$Ψ$ is a conjunction of several formulas:
	\begin{itemize}
		\item $L$ is a linear order.
		\item Tape and state are well-defined and the machine eventually arrives in an accepting state. Exactly as in the proof of Trakhtenbrot.
		\item Sentences describing the transition function: For $a ∈ Δ, q ∈ Q$,
		\begin{equation*}
		\bigvee_{(q',a',mv) ∈ δ(q,a)} α_{(q,a,q',a',mv)},
		\end{equation*}
		where $α_{(q,a,q',a',mv)}$ is as in the previous proof.
		\item A formula describing the initial state of the tape (i.e. $enc(\A)$):
		\begin{equation*}
		∀\bar{p}∀\bar{t}\left(¬∃\bar{u} (\bar{u} <_k \bar{t}) → \left[
		\begin{array}{rcl}
		ι(\bar{p},\bar{t})&\leftrightarrow&T_1(\bar{p},\bar{t})\\
		∧\ ξ(\bar{p},\bar{t})&\leftrightarrow&T_{\_}(\bar{p},\bar{t})
		\end{array}		
		\right]\right)
		\end{equation*}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Construction of $ι(\bar{p})$ and $ξ(\bar{p})$}
	\begin{align*}
	ι(\bar{p}) &\leftrightarrow enc(\A) \text{ contains $1$ at position } \bar{p}\\
	ξ(\bar{p}) &\leftrightarrow \bar{p} \text{ is outside of } enc(\A)
	\end{align*}	
	Example: $\A = (A, E)$ graph with $n$ elements $\{0,…,n-1\}$
	
	$enc(\A) = 0^n1s$, with $s$ a string of length $n^2$ that encodes $E$:
	\begin{equation*}
	s(in+j) = 1 \leftrightarrow i E j
	\end{equation*}
	
	Suppose $k = 3$. Then a tuple $\bar{p} = (p_1,p_2,p_3)$ represents the position $p_1 n^2 + p_2 n + p_3$.
	
	Encoding of $E$ runs from position $n+1$ to $n^2 + n$.
	
%	\begin{align*}
%	p_1 > 1 &\Rightarrow ι(\bar{p}) = \bot\\
%	p_1 = p_2 = 0 &\Rightarrow ι(\bar{p}) = \bot\\
%	p_1 = 0, p_2,p_3 \neq 0 &\Rightarrow ι(\bar{p}) = E(p_2-1, p_3-1)\\
%	p_1 = p_3 = 0, p_2 \neq 0 &\Rightarrow ι(\bar{p}) = E(p_2-2, n-1)
%	\end{align*}

	\begin{align*}
	ι(\bar{p}) &= \left[\left(\begin{array}{rcl}
	p_1 &=& 0 \\
	∧\ p_2 &>& 0
	\end{array}\right) ∧ \left(\begin{array}{rclcl}
	p_3 &\neq& 0 &∧& E(p_2-1, p_3-1)\\
	∨\ p_3 &=& 0 &∧& E(p_2-2, n-1)
	\end{array}\right)\right]\\
	&∨\ \left[p_1 = 0 ∧ p_2 = 1 ∧ p_3 = 0\right] ∨ \left[p_1 = 1 ∧ … \right]
	\end{align*}
\end{frame}


\end{document}
